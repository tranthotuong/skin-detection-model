{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Aa36bMKLze3z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lnzRzk7e44HL",
    "outputId": "6d1e2d2f-1669-42a6-f6a7-45a52b73ce41"
   },
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv('D:/New_Capstone/Casptone/Data/HAM10000/HAM10000_metadata.csv')\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlR6SjeEzXsm"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join('D:/New_Capstone/Casptone/Data/Data-model', 'train_dir')\n",
    "vali_dir = os.path.join('D:/New_Capstone/Casptone/Data/Data-model', 'vali_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join('D:/New_Capstone/Casptone/Data/Data-model', 'test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "_IFqPgUu5jPj",
    "outputId": "979e5d51-8319-435c-f4db-1981b452c849"
   },
   "outputs": [],
   "source": [
    "df_count = data_pd.groupby('lesion_id').count()\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjMQNZRI2xl7"
   },
   "outputs": [],
   "source": [
    "df_count = df_count[df_count['dx'] == 1]\n",
    "df_count.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeVfs-Ly95gs"
   },
   "outputs": [],
   "source": [
    "def duplicates(x):\n",
    "    unique = set(df_count['lesion_id'])\n",
    "    if x in unique:\n",
    "        return 'no' \n",
    "    else:\n",
    "        return 'duplicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2WZZRSzO5v8t",
    "outputId": "5042fd49-03f1-48a6-ed7b-ac849f1fe0c9"
   },
   "outputs": [],
   "source": [
    "data_pd['is_duplicate'] = data_pd['lesion_id'].apply(duplicates)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BhGlAv0yAHu"
   },
   "outputs": [],
   "source": [
    "df_count = data_pd[data_pd['is_duplicate'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3ndAO_Ex5fb"
   },
   "outputs": [],
   "source": [
    "train, vali_df = train_test_split(df_count, test_size=0.45, stratify=df_count['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('D:/New_Capstone/Casptone/Data/HAM10000/ISIC2018_Task3_Test_GroundTruth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T7w2kYUdNkjX",
    "outputId": "5b6b9660-79f4-4fdb-ec79-4d5366f99a3e"
   },
   "outputs": [],
   "source": [
    "def identify_trainOrtest(x):\n",
    "    vali_data = set(vali_df['image_id'])\n",
    "    if str(x) in vali_data:\n",
    "        return 'vali'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "#creating train_df\n",
    "data_pd['train_vali_split'] = data_pd['image_id'].apply(identify_trainOrtest)\n",
    "train_df = data_pd[data_pd['train_vali_split'] == 'train']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('D:/New_Capstone/Casptone/Data/Data-model/Dataset_model_split45_clean.csv')\n",
    "vali_df= pd.read_csv('D:/New_Capstone/Casptone/Ham10000 models/Model without Soft Attention/vali_df_split45.csv')\n",
    "test_df= pd.read_csv('D:/New_Capstone/Casptone/Data/HAM10000/ISIC2018_Task3_Test_GroundTruth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FPySEG1m58pu",
    "outputId": "18fd6e44-8d62-4a88-efa7-d29aa64637ae"
   },
   "outputs": [],
   "source": [
    "vali_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ja7jQJQb39wi"
   },
   "outputs": [],
   "source": [
    "# Image id of train and test images\n",
    "train_list = list(train_df['image_id'])\n",
    "vali_list = list(vali_df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(test_df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_luong_benh = train_df['dx'].value_counts()\n",
    "so_luong_benh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_luong_benh = vali_df['dx'].value_counts()\n",
    "so_luong_benh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_luong_benh = test_df['dx'].value_counts()\n",
    "so_luong_benh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 45\n",
    "df_count.to_csv(f'df_count_split{split}.csv')\n",
    "train_df.to_csv(f'train_df_split{split}.csv')\n",
    "vali_df.to_csv(f'vali_df_split{split}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBJgBAjP13q5",
    "outputId": "463d1b3f-d77c-49b0-d89e-9ce5d21a47e0"
   },
   "outputs": [],
   "source": [
    "len(vali_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEChk1DK-H8Z",
    "outputId": "612e1f17-9db3-4dea-c99e-0b7aa5ee566a"
   },
   "outputs": [],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIoMqylGAYYZ"
   },
   "outputs": [],
   "source": [
    "# Set the image_id as the index in data_pd\n",
    "train_df.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_df.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ja_PtDYyDPMM"
   },
   "outputs": [],
   "source": [
    "os.mkdir(train_dir)\n",
    "os.mkdir(vali_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsoqCvNsgmHP"
   },
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KYMTQugCmRR"
   },
   "outputs": [],
   "source": [
    "for i in targetnames:\n",
    "  directory1=train_dir+'/'+i\n",
    "  directory2=vali_dir+'/'+i\n",
    "  os.mkdir(directory1)\n",
    "  os.mkdir(directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in targetnames:\n",
    "  directory3=test_dir+'/'+i\n",
    "  os.mkdir(directory3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GL9vFa3X-ty1"
   },
   "outputs": [],
   "source": [
    "for image in train_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = train_df.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join('D:/New_Capstone/Casptone/Data/Data-model/Dataset_images_split45', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(train_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwbKrEzJ_if2"
   },
   "outputs": [],
   "source": [
    "for image in vali_list:\n",
    "\n",
    "    file_name = image+'.jpg'\n",
    "    label = vali_df.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join('D:/New_Capstone/Casptone/Data/HAM10000/HAM10000_images', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(vali_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in test_list:\n",
    "\n",
    "    file_name = image+'.jpg'\n",
    "    label = test_df.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join('D:/New_Capstone/Casptone/Data/HAM10000/ISIC2018_Task3_Test_Images/ISIC2018_Task3_Test_Images', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(test_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4W8hmE2OHjQa",
    "outputId": "e57e21fb-559b-40f8-8755-d8e45bd3e8a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2068 images belonging to 1 classes.\n",
      "Found 4707 images belonging to 1 classes.\n",
      "Found 4572 images belonging to 1 classes.\n",
      "Found 239 images belonging to 1 classes.\n",
      "Found 5153 images belonging to 1 classes.\n",
      "Found 4415 images belonging to 1 classes.\n",
      "Found 253 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "# Augmenting images and storing them in temporary directories \n",
    "for img_class in targetnames:\n",
    "\n",
    "    #creating temporary directories\n",
    "    # creating a base directory\n",
    "    aug_dir = 'D:/New_Capstone/Casptone/Data/Data-model/aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    # creating a subdirectory inside the base directory for images of the same class\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    img_list = os.listdir('D:/New_Capstone/Casptone/Data/Data-model/train_dir/' + img_class)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir \n",
    "    for file_name in img_list:\n",
    "\n",
    "        # path of source image in training directory\n",
    "        source = os.path.join('D:/New_Capstone/Casptone/Data/Data-model/train_dir/' + img_class, file_name)\n",
    "\n",
    "        # creating a target directory to send images \n",
    "        target = os.path.join(img_dir, file_name)\n",
    "\n",
    "        # copying the image from the source to target file\n",
    "        shutil.copyfile(source, target)\n",
    "\n",
    "    # Temporary augumented dataset directory.\n",
    "    source_path = aug_dir\n",
    "\n",
    "    # Augmented images will be saved to training directory\n",
    "    save_path = 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/' + img_class\n",
    "\n",
    "    # Creating Image Data Generator to augment images\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        brightness_range=[0.2,1.2],\n",
    "    )\n",
    "\n",
    "    \n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(source_path,save_to_dir=save_path,save_format='jpg',target_size=(224, 224),batch_size=batch_size)\n",
    "    \n",
    "    # Generate the augmented images\n",
    "    aug_images = 20000 \n",
    "\n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
    "\n",
    "    # creating 8000 augmented images per class\n",
    "    for i in range(0, num_batches):\n",
    "        images, labels = next(aug_datagen)\n",
    "\n",
    "    # delete temporary directory \n",
    "    shutil.rmtree('D:/New_Capstone/Casptone/Data/Data-model/aug_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng file hình ảnh trong thư mục 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/akiec': 19762\n",
      "Số lượng file hình ảnh trong thư mục 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/bcc': 19878\n",
      "Số lượng file hình ảnh trong thư mục 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/bkl': 19938\n",
      "Số lượng file hình ảnh trong thư mục 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/df': 19170\n",
      "Số lượng file hình ảnh trong thư mục 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/mel': 19909\n",
      "Số lượng file hình ảnh trong thư mục 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/nv': 19910\n",
      "Số lượng file hình ảnh trong thư mục 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/vasc': 16948\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def dem_so_luong_anh(folder_path, extensions=['jpg', 'jpeg', 'png', 'gif']):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Thư mục '{folder_path}' không tồn tại.\")\n",
    "        return\n",
    "\n",
    "    danh_sach_anh = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "    so_luong_anh = 0\n",
    "    for file in danh_sach_anh:\n",
    "        phan_mo_rong = file.split('.')[-1].lower()\n",
    "        if phan_mo_rong in extensions:\n",
    "            so_luong_anh += 1\n",
    "\n",
    "    print(f\"Số lượng file hình ảnh trong thư mục '{folder_path}': {so_luong_anh}\")\n",
    "\n",
    "folder_path = 'D:/New_Capstone/Casptone/Data/Data-model/train_dir/'\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "for i in targetnames:\n",
    "    dem_so_luong_anh(folder_path+i)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
